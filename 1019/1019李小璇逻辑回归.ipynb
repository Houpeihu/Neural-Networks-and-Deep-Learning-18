{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sigmoid函数\n",
    "def sigmoid(z):\n",
    "    sigmoid=1.0/(1.0+np.exp(-z))\n",
    "    return sigmoid\n",
    "\n",
    "def regularize(x):#数据标准化处理归一化函数\n",
    "    x_tmp=x.copy()\n",
    "    for i in range(0,len(x[0])):\n",
    "        current_x=x_tmp[:,i]#x的每一列=current_x\n",
    "        x_avg=np.mean(current_x)#取平均\n",
    "        x_var=current_x.max()-current_x.min()\n",
    "        current_x=(current_x-x_avg)/(x_var)\n",
    "        x_tmp[:,i]=current_x\n",
    "    return x_tmp\n",
    "\n",
    "#cross entropy 函数 交叉熵函数\n",
    "def loss(h,y):\n",
    "    loss=(-y*np.log(h)-(1-y)*np.log(1-h)).mean()\n",
    "    return loss\n",
    "\n",
    "#梯度下降 计算梯度\n",
    "def gradient(X,h,y):\n",
    "    gradient=np.dot(X.T,(h-y))/y.shape[0] #除以y的行数\n",
    "    return gradient\n",
    "#逻辑回归优化过程\n",
    "def Logistic_Regression(X,y,stepsize,max_iters): \n",
    "    intercept=np.ones((X.shape[0],1)) #初始化截距为1\n",
    "    X=np.concatenate((intercept,X),axis=1)\n",
    "    w=np.zeros((X.shape[1],1))#初始化参数为0（3，1）\n",
    "    l_history=np.zeros((max_iters,1)) #初始化损失值\n",
    "    \n",
    "    for i in range(0,max_iters):\n",
    "        z=np.dot(X,w)#线性函数\n",
    "        h=sigmoid(z)\n",
    "        #计算梯度\n",
    "        g=gradient(X,h,y)\n",
    "        #更新参数\n",
    "        w-=stepsize*g\n",
    "        #计算更新后的损失\n",
    "        l_history[i]=loss(h,y)\n",
    "    return l_history,w\n",
    "#逻辑回归预测函数\n",
    "def Logistic_Regression_predict(test_X,test_label,stepsize,max_iters):\n",
    "    #w=np.zeros((3,1))\n",
    "    accuracy=np.zeros((max_iters,1))\n",
    "    \n",
    "    for i in range(0,max_iters):\n",
    "        _,w=Logistic_Regression(train_X,train_label,stepsize,i)\n",
    "        #只给w赋值\n",
    "        predict_z=np.dot(test_X1,w)\n",
    "        predict_label=sigmoid(predict_z)\n",
    "        #二分类\n",
    "        predict_label[predict_label<0.5]=0\n",
    "        predict_label[predict_label>0.5]=1\n",
    "        accuracy[i]=(predict_label==test_label).mean()#计算预测准确率\n",
    "    return accuracy\n",
    "#主函数\n",
    "#先导入csv函数\n",
    "filepath='D:\\\\semester2020.2\\\\Neutral Network\\\\作业1019\\\\S(1).csv'\n",
    "data=np.loadtxt(filepath,delimiter=',',skiprows=1,dtype='float')\n",
    "X=data[:,0:2]\n",
    "y=data[:,2:3]\n",
    "X=regularize(X)\n",
    "#划分测试训练集\n",
    "train_X=X[0:300,:]\n",
    "test_X=X[300:,:]\n",
    "train_label=y[0:300,:]\n",
    "test_label=y[300:,:]\n",
    "#逻辑回归模型训练及预测\n",
    "max_iters=2000\n",
    "stepsize=0.05\n",
    "l_history,w=Logistic_Regression(train_X,train_label,stepsize,max_iters)\n",
    "#训练模型\n",
    "intercept=np.ones((test_X.shape[0],1))\n",
    "test_X1=np.concatenate((intercept,test_X),axis=1)\n",
    "accuracy=Logistic_Regression_predict(test_X1,test_label,stepsize,max_iters)\n",
    "\n",
    "x_col=np.arange(0,max_iters)\n",
    "plt.plot(x_col,accuracy,'-b')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt('accuracy')\n",
    "plt.show()\n",
    "\n",
    "#画出cost的变化趋势\n",
    "x_col=np.arange(0,max_iters)\n",
    "plt.plot(x_col,l_history,'-b')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost J')\n",
    "plt.show()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
